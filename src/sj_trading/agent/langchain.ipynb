{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81835749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.llms import VLLM\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "hf_token = os.getenv('hf_token')\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a9dafc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 05:31:57 [config.py:717] This model supports multiple tasks: {'reward', 'embed', 'generate', 'classify', 'score'}. Defaulting to 'generate'.\n",
      "INFO 06-03 05:31:57 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=8192.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/transformers_utils/tokenizer_group.py:23: FutureWarning: It is strongly recommended to run mistral models with `--tokenizer-mode \"mistral\"` to ensure correct encoding and decoding.\n",
      "  self.tokenizer = get_tokenizer(self.tokenizer_id, **tokenizer_config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-03 05:32:03 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='mistralai/Mistral-7B-Instruct-v0.3', speculative_config=None, tokenizer='mistralai/Mistral-7B-Instruct-v0.3', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=mistralai/Mistral-7B-Instruct-v0.3, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 06-03 05:32:04 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7fe9dde14f10>\n",
      "INFO 06-03 05:32:04 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 06-03 05:32:04 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 06-03 05:32:04 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 06-03 05:32:04 [gpu_model_runner.py:1329] Starting to load model mistralai/Mistral-7B-Instruct-v0.3...\n",
      "ERROR 06-03 05:32:05 [core.py:396] EngineCore failed to start.\n",
      "ERROR 06-03 05:32:05 [core.py:396] Traceback (most recent call last):\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 387, in run_engine_core\n",
      "ERROR 06-03 05:32:05 [core.py:396]     engine_core = EngineCoreProc(*args, **kwargs)\n",
      "ERROR 06-03 05:32:05 [core.py:396]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 329, in __init__\n",
      "ERROR 06-03 05:32:05 [core.py:396]     super().__init__(vllm_config, executor_class, log_stats,\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 64, in __init__\n",
      "ERROR 06-03 05:32:05 [core.py:396]     self.model_executor = executor_class(vllm_config)\n",
      "ERROR 06-03 05:32:05 [core.py:396]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/executor/executor_base.py\", line 52, in __init__\n",
      "ERROR 06-03 05:32:05 [core.py:396]     self._init_executor()\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/executor/uniproc_executor.py\", line 47, in _init_executor\n",
      "ERROR 06-03 05:32:05 [core.py:396]     self.collective_rpc(\"load_model\")\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/executor/uniproc_executor.py\", line 56, in collective_rpc\n",
      "ERROR 06-03 05:32:05 [core.py:396]     answer = run_method(self.driver_worker, method, args, kwargs)\n",
      "ERROR 06-03 05:32:05 [core.py:396]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/utils.py\", line 2456, in run_method\n",
      "ERROR 06-03 05:32:05 [core.py:396]     return func(*args, **kwargs)\n",
      "ERROR 06-03 05:32:05 [core.py:396]            ^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/worker/gpu_worker.py\", line 162, in load_model\n",
      "ERROR 06-03 05:32:05 [core.py:396]     self.model_runner.load_model()\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/worker/gpu_model_runner.py\", line 1332, in load_model\n",
      "ERROR 06-03 05:32:05 [core.py:396]     self.model = get_model(vllm_config=self.vllm_config)\n",
      "ERROR 06-03 05:32:05 [core.py:396]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/model_loader/__init__.py\", line 14, in get_model\n",
      "ERROR 06-03 05:32:05 [core.py:396]     return loader.load_model(vllm_config=vllm_config)\n",
      "ERROR 06-03 05:32:05 [core.py:396]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/model_loader/loader.py\", line 452, in load_model\n",
      "ERROR 06-03 05:32:05 [core.py:396]     model = _initialize_model(vllm_config=vllm_config)\n",
      "ERROR 06-03 05:32:05 [core.py:396]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/model_loader/loader.py\", line 133, in _initialize_model\n",
      "ERROR 06-03 05:32:05 [core.py:396]     return model_class(vllm_config=vllm_config, prefix=prefix)\n",
      "ERROR 06-03 05:32:05 [core.py:396]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py\", line 496, in __init__\n",
      "ERROR 06-03 05:32:05 [core.py:396]     self.model = self._init_model(vllm_config=vllm_config,\n",
      "ERROR 06-03 05:32:05 [core.py:396]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py\", line 542, in _init_model\n",
      "ERROR 06-03 05:32:05 [core.py:396]     return LlamaModel(vllm_config=vllm_config,\n",
      "ERROR 06-03 05:32:05 [core.py:396]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/compilation/decorators.py\", line 151, in __init__\n",
      "ERROR 06-03 05:32:05 [core.py:396]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py\", line 321, in __init__\n",
      "ERROR 06-03 05:32:05 [core.py:396]     self.start_layer, self.end_layer, self.layers = make_layers(\n",
      "ERROR 06-03 05:32:05 [core.py:396]                                                     ^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/utils.py\", line 609, in make_layers\n",
      "ERROR 06-03 05:32:05 [core.py:396]     [PPMissingLayer() for _ in range(start_layer)] + [\n",
      "ERROR 06-03 05:32:05 [core.py:396]                                                      ^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/utils.py\", line 610, in <listcomp>\n",
      "ERROR 06-03 05:32:05 [core.py:396]     maybe_offload_to_cpu(layer_fn(prefix=f\"{prefix}.{idx}\"))\n",
      "ERROR 06-03 05:32:05 [core.py:396]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py\", line 323, in <lambda>\n",
      "ERROR 06-03 05:32:05 [core.py:396]     lambda prefix: layer_type(config=config,\n",
      "ERROR 06-03 05:32:05 [core.py:396]                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py\", line 239, in __init__\n",
      "ERROR 06-03 05:32:05 [core.py:396]     self.self_attn = LlamaAttention(\n",
      "ERROR 06-03 05:32:05 [core.py:396]                      ^^^^^^^^^^^^^^^\n",
      "ERROR 06-03 05:32:05 [core.py:396]   File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py\", line 135, in __init__\n",
      "ERROR 06-03 05:32:05 [core.py:396]     self.q_size = self.num_heads * self.head_dim\n",
      "ERROR 06-03 05:32:05 [core.py:396]                   ~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "ERROR 06-03 05:32:05 [core.py:396] TypeError: unsupported operand type(s) for *: 'int' and 'NoneType'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process EngineCore_0:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/.local/share/uv/python/cpython-3.11.12-linux-x86_64-gnu/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 400, in run_engine_core\n",
      "    raise e\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 387, in run_engine_core\n",
      "    engine_core = EngineCoreProc(*args, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 329, in __init__\n",
      "    super().__init__(vllm_config, executor_class, log_stats,\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/engine/core.py\", line 64, in __init__\n",
      "    self.model_executor = executor_class(vllm_config)\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/executor/executor_base.py\", line 52, in __init__\n",
      "    self._init_executor()\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/executor/uniproc_executor.py\", line 47, in _init_executor\n",
      "    self.collective_rpc(\"load_model\")\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/executor/uniproc_executor.py\", line 56, in collective_rpc\n",
      "    answer = run_method(self.driver_worker, method, args, kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/utils.py\", line 2456, in run_method\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/worker/gpu_worker.py\", line 162, in load_model\n",
      "    self.model_runner.load_model()\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/worker/gpu_model_runner.py\", line 1332, in load_model\n",
      "    self.model = get_model(vllm_config=self.vllm_config)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/model_loader/__init__.py\", line 14, in get_model\n",
      "    return loader.load_model(vllm_config=vllm_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/model_loader/loader.py\", line 452, in load_model\n",
      "    model = _initialize_model(vllm_config=vllm_config)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/model_loader/loader.py\", line 133, in _initialize_model\n",
      "    return model_class(vllm_config=vllm_config, prefix=prefix)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py\", line 496, in __init__\n",
      "    self.model = self._init_model(vllm_config=vllm_config,\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py\", line 542, in _init_model\n",
      "    return LlamaModel(vllm_config=vllm_config,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/compilation/decorators.py\", line 151, in __init__\n",
      "    old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py\", line 321, in __init__\n",
      "    self.start_layer, self.end_layer, self.layers = make_layers(\n",
      "                                                    ^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/utils.py\", line 609, in make_layers\n",
      "    [PPMissingLayer() for _ in range(start_layer)] + [\n",
      "                                                     ^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/utils.py\", line 610, in <listcomp>\n",
      "    maybe_offload_to_cpu(layer_fn(prefix=f\"{prefix}.{idx}\"))\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py\", line 323, in <lambda>\n",
      "    lambda prefix: layer_type(config=config,\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py\", line 239, in __init__\n",
      "    self.self_attn = LlamaAttention(\n",
      "                     ^^^^^^^^^^^^^^^\n",
      "  File \"/root/sj_Trading/.venv/lib/python3.11/site-packages/vllm/model_executor/models/llama.py\", line 135, in __init__\n",
      "    self.q_size = self.num_heads * self.head_dim\n",
      "                  ~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~\n",
      "TypeError: unsupported operand type(s) for *: 'int' and 'NoneType'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Engine core initialization failed. See root cause above.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m llm = \u001b[43mVLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmistralai/Mistral-7B-Instruct-v0.3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(llm.invoke(\u001b[33m\"\u001b[39m\u001b[33mWhat is the capital of France?\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sj_Trading/.venv/lib/python3.11/site-packages/langchain_core/load/serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sj_Trading/.venv/lib/python3.11/site-packages/pydantic/_internal/_decorators_v1.py:148\u001b[39m, in \u001b[36mmake_v1_generic_root_validator.<locals>._wrapper1\u001b[39m\u001b[34m(values, _)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapper1\u001b[39m(values: RootValidatorValues, _: core_schema.ValidationInfo) -> RootValidatorValues:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sj_Trading/.venv/lib/python3.11/site-packages/langchain_core/utils/pydantic.py:226\u001b[39m, in \u001b[36mpre_init.<locals>.wrapper\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m    223\u001b[39m             values[name] = field_info.default\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Call the decorated function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sj_Trading/.venv/lib/python3.11/site-packages/langchain_community/llms/vllm.py:89\u001b[39m, in \u001b[36mVLLM.validate_environment\u001b[39m\u001b[34m(cls, values)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m     84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     85\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import vllm python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     86\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install vllm`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     87\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m values[\u001b[33m\"\u001b[39m\u001b[33mclient\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mVLLModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensor_parallel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtensor_parallel_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrust_remote_code\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdownload_dir\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvllm_kwargs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sj_Trading/.venv/lib/python3.11/site-packages/vllm/utils.py:1161\u001b[39m, in \u001b[36mdeprecate_args.<locals>.wrapper.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1154\u001b[39m             msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1156\u001b[39m         warnings.warn(\n\u001b[32m   1157\u001b[39m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[32m   1158\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[32m   1159\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sj_Trading/.venv/lib/python3.11/site-packages/vllm/entrypoints/llm.py:247\u001b[39m, in \u001b[36mLLM.__init__\u001b[39m\u001b[34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_token, hf_overrides, mm_processor_kwargs, task, override_pooler_config, compilation_config, **kwargs)\u001b[39m\n\u001b[32m    217\u001b[39m engine_args = EngineArgs(\n\u001b[32m    218\u001b[39m     model=model,\n\u001b[32m    219\u001b[39m     task=task,\n\u001b[32m   (...)\u001b[39m\u001b[32m    243\u001b[39m     **kwargs,\n\u001b[32m    244\u001b[39m )\n\u001b[32m    246\u001b[39m \u001b[38;5;66;03m# Create the Engine (autoselects V0 vs V1)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m \u001b[38;5;28mself\u001b[39m.llm_engine = \u001b[43mLLMEngine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUsageContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_class = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m.llm_engine)\n\u001b[32m    251\u001b[39m \u001b[38;5;28mself\u001b[39m.request_counter = Counter()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sj_Trading/.venv/lib/python3.11/site-packages/vllm/engine/llm_engine.py:510\u001b[39m, in \u001b[36mLLMEngine.from_engine_args\u001b[39m\u001b[34m(cls, engine_args, usage_context, stat_loggers)\u001b[39m\n\u001b[32m    507\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv1\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMEngine \u001b[38;5;28;01mas\u001b[39;00m V1LLMEngine\n\u001b[32m    508\u001b[39m     engine_cls = V1LLMEngine\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mengine_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_vllm_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py:112\u001b[39m, in \u001b[36mLLMEngine.from_vllm_config\u001b[39m\u001b[34m(cls, vllm_config, usage_context, stat_loggers, disable_log_stats)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_vllm_config\u001b[39m(\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    110\u001b[39m     disable_log_stats: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    111\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLLMEngine\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m               \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mExecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m               \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m               \u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m               \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m               \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVLLM_ENABLE_V1_MULTIPROCESSING\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/engine/llm_engine.py:92\u001b[39m, in \u001b[36mLLMEngine.__init__\u001b[39m\u001b[34m(self, vllm_config, executor_class, log_stats, usage_context, stat_loggers, mm_registry, use_cached_outputs, multiprocess_mode)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28mself\u001b[39m.output_processor = OutputProcessor(\u001b[38;5;28mself\u001b[39m.tokenizer,\n\u001b[32m     89\u001b[39m                                         log_stats=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# EngineCore (gets EngineCoreRequests and gives EngineCoreOutputs)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m \u001b[38;5;28mself\u001b[39m.engine_core = \u001b[43mEngineCoreClient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmultiprocess_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43masyncio_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# FIXME: implement\u001b[39;49;00m\n\u001b[32m     98\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m multiprocess_mode:\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# for v0 compatibility\u001b[39;00m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_executor = \u001b[38;5;28mself\u001b[39m.engine_core.engine_core.model_executor\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/engine/core_client.py:73\u001b[39m, in \u001b[36mEngineCoreClient.make_client\u001b[39m\u001b[34m(multiprocess_mode, asyncio_mode, vllm_config, executor_class, log_stats)\u001b[39m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m AsyncMPClient(vllm_config, executor_class, log_stats)\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m multiprocess_mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m asyncio_mode:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSyncMPClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m InprocClient(vllm_config, executor_class, log_stats)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/engine/core_client.py:494\u001b[39m, in \u001b[36mSyncMPClient.__init__\u001b[39m\u001b[34m(self, vllm_config, executor_class, log_stats)\u001b[39m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, vllm_config: VllmConfig, executor_class: \u001b[38;5;28mtype\u001b[39m[Executor],\n\u001b[32m    493\u001b[39m              log_stats: \u001b[38;5;28mbool\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43masyncio_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvllm_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m     \u001b[38;5;28mself\u001b[39m.outputs_queue = queue.Queue[Union[EngineCoreOutputs, \u001b[38;5;167;01mException\u001b[39;00m]]()\n\u001b[32m    503\u001b[39m     \u001b[38;5;66;03m# Ensure that the outputs socket processing thread does not have\u001b[39;00m\n\u001b[32m    504\u001b[39m     \u001b[38;5;66;03m# a ref to the client which prevents gc.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/engine/core_client.py:398\u001b[39m, in \u001b[36mMPClient.__init__\u001b[39m\u001b[34m(self, asyncio_mode, vllm_config, executor_class, log_stats)\u001b[39m\n\u001b[32m    394\u001b[39m \u001b[38;5;28mself\u001b[39m._init_core_engines(vllm_config, new_core_engine,\n\u001b[32m    395\u001b[39m                         \u001b[38;5;28mself\u001b[39m.resources.core_engines)\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# Wait for engine core process(es) to start.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_engine_startup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[38;5;28mself\u001b[39m.utility_results: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, AnyFuture] = {}\n\u001b[32m    402\u001b[39m \u001b[38;5;66;03m# Request objects which may contain pytorch-allocated tensors\u001b[39;00m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# that we need to keep references to until zmq is done with the\u001b[39;00m\n\u001b[32m    404\u001b[39m \u001b[38;5;66;03m# underlying data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sj_Trading/.venv/lib/python3.11/site-packages/vllm/v1/engine/core_client.py:430\u001b[39m, in \u001b[36mMPClient._wait_for_engine_startup\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    427\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(events) > \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m events[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m] != sync_input_socket:\n\u001b[32m    429\u001b[39m     \u001b[38;5;66;03m# One of the core processes exited.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mEngine core initialization failed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    431\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mSee root cause above.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    433\u001b[39m eng_id_bytes, msg = sync_input_socket.recv_multipart()\n\u001b[32m    434\u001b[39m eng_id = \u001b[38;5;28mint\u001b[39m.from_bytes(eng_id_bytes, byteorder=\u001b[33m\"\u001b[39m\u001b[33mlittle\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Engine core initialization failed. See root cause above."
     ]
    }
   ],
   "source": [
    "llm = VLLM(\n",
    "    model=\"model_name\",\n",
    "    trust_remote_code=True,\n",
    "    max_new_tokens=128,\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    temperature=0.8,\n",
    ")\n",
    "\n",
    "print(llm.invoke(\"What is the capital of France?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
